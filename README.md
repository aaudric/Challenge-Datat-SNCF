# ğŸš‰ PrÃ©diction des Validations JournalieÌ€res par Gare - SNCF Transilien

Projet rÃ©alisÃ© dans le cadre du Master 2 MIASHS (UniversitÃ© Montpellier III) pour le challenge organisÃ© par SNCF-Transilien sur [Challenge Data](https://challengedata.ens.fr/participants/challenges/149/).

---

## ğŸ“Œ Contexte

SNCF-Transilien, opÃ©rateur des trains de banlieue en Ãle-de-France, fait circuler plus de 6 200 trains et transporte 3,2 millions de voyageurs chaque jour. Ces derniers valident leur titre de transport en moyenne **2,3 millions de fois par jour**.

ğŸ¯ **Objectif** : PrÃ©dire Ã  moyen-long terme le **nombre de validations par jour et par gare**, afin de :

- Anticiper les volumes de voyageurs
- Mieux comprendre les dynamiques dâ€™affluence
- Accompagner les Ã©volutions du rÃ©seau de transport

---

## ğŸ—ƒï¸ DonnÃ©es

- **Train.csv** : 1 237 971 lignes (2015â€“2022)
- **Test.csv** : 78 652 lignes (janvierâ€“juin 2023)
- **Nombre de gares** : 448 gares distinctes
- **Colonnes** :
  - `date` : jour de validation
  - `station` : identifiant anonymisÃ© de la gare
  - `job`, `ferie`, `vacances` : indicateurs contextuels
  - `y` : nombre de validations

### ğŸ›  Feature Engineering

- Variables temporelles : `weekday`, `weekofyear`, `month`, `quarter`, etc.
- Variables de retard : `lag_1_log`, `lag_7_log`, `lag_30_log`, `lag_365_log`
- Encodage des stations
- Transformation logarithmique de `y`

---

## ğŸ“Š Analyse Exploratoire

- Tendance haussiÃ¨re entre 2015 et 2019
- Chute brutale en 2020 (COVID-19), reprise Ã  partir de 2021
- SaisonnalitÃ© hebdomadaire forte (pics tous les 7 jours)
- AutocorrÃ©lation significative jusquâ€™Ã  60 jours

---

## ğŸ§  ModÃ©lisation

### MÃ©thodes explorÃ©es

- Approches classiques : SARIMA, ARIMA, Prophet
- Machine Learning : XGBoost, LightGBM
- Deep Learning : CNN, LSTM, GRU
- Transformers pour sÃ©ries temporelles multivariÃ©es

### StratÃ©gies COVID

- Ajout dâ€™une variable indicatrice COVID
- Remplacement ou lissage des valeurs anormales
- Apprentissage uniquement post-COVID (2021+)

---

## ğŸ§® MÃ©trique d'Ã‰valuation

La mÃ©trique utilisÃ©e pour Ã©valuer les performances est le **MAPE** (*Mean Absolute Percentage Error*), dÃ©finie comme : 
$$
\text{MAPE} = \frac{1}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
$$
---

## ğŸ† RÃ©sultats

### ğŸ¥‡ Meilleur ModÃ¨le

- **ModÃ¨le** : `XGBoost` par station (post-COVID uniquement)
- **Features** : Feature engineering + indicateurs contextuels
- **Score public (MAPE)** : **143.64**
- **Classement final** : **66áµ‰ sur 200 participants**
- **Benchmark officiel du challenge** : 177.08 (91áµ‰ place)

### Classement des soumissions par score public (MAPE)

| Rang | MÃ©thode                            | Features                                      | MAPE |
|------|------------------------------------|-----------------------------------------------|------|
| 1    | XGBoost par station post-COVID     | Feature engineering + indicateurs contextuels | **143.64** |
| 2    | XGBoost par station                | Feature engineering + indicateurs contextuels | 150.22 |
| 3    | XGBoost par station                | Indicateurs contextuels uniquement            | 182.66 |
| 4    | XGBoost post-COVID                 | Feature engineering + indicateurs contextuels | 217.43 |
| 5    | SARIMA                             | Feature engineering + indicateurs contextuels | 231.04 |
| 6    | LightGBM post-COVID                | Feature engineering + indicateurs contextuels | 252.35 |
| 7    | Projection tendances 2021â€“2022     | Copie 2022 + âˆ†(2021âˆ’2022)                     | 349.52 |

---

## ğŸ” Analyse des RÃ©sidus

- Erreurs plus Ã©levÃ©es pour les faibles affluences â†’ instabilitÃ© (hÃ©tÃ©roscÃ©dasticitÃ©)
- Bonne prÃ©cision pour les fortes affluences (â‰¥ 100 000 validations)
- Erreurs globalement symÃ©triques mais prÃ©sence dâ€™outliers

---

## ğŸ”® Perspectives

- Clustering des gares pour des modÃ¨les spÃ©cialisÃ©s
- IntÃ©gration de donnÃ©es externes (Ã©vÃ©nements, mÃ©tÃ©oâ€¦)
- Analyse des outliers pour comprendre les anomalies
- ExpÃ©rimentation de modÃ¨les hybrides (LSTM + XGBoost, etc.)

---

## ğŸ–¼ï¸ Poster du Projet

ğŸ“ Un rÃ©sumÃ© visuel du projet est disponible ici : [`poster.pdf`](./poster/poster.pdf)

---

## ğŸ“š RÃ©fÃ©rences
Voir le dossier [LittÃ©rature](./LittÃ©rature/) du dÃ©pÃ´t.


---

Â© **Audric Girondin** â€” Master 2 MIASHS, UniversitÃ© Montpellier III

